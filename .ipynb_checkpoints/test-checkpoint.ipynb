{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9beecd41-49f0-4fe4-aad8-2c4d125dc3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/extract.py\n",
    "\n",
    "import pandas as pd\n",
    "from utils.config import load_config\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "29a00bdf-c210-4b54-ab36-c32917a97df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/feature_engineering.py\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def convert_salary_to_numeric(df):\n",
    "    \"\"\"\n",
    "    Converts the 'salary' column to a numeric format (removes currency symbols, commas).\n",
    "    \"\"\"\n",
    "    df['salary_numeric'] = df['salary'].replace({'â‚¹': '', '/yr': '', ',': ''}, regex=True).astype(float)\n",
    "    return df\n",
    "\n",
    "def add_salary_band(df):\n",
    "    \"\"\"\n",
    "    Adds a salary band column for easier grouping.\n",
    "    \"\"\"\n",
    "    bins = [0, 500000, 1000000, 1500000, 2000000, float('inf')]\n",
    "    labels = ['<5L', '5-10L', '10-15L', '15-20L', '20L+']\n",
    "    df['salary_band'] = pd.cut(df['salary_numeric'], bins=bins, labels=labels)\n",
    "    return df\n",
    "\n",
    "def compute_avg_salary_by_group(df, group_col):\n",
    "    \"\"\"\n",
    "    Computes the average salary grouped by a specified column.\n",
    "    \"\"\"\n",
    "    avg_salary = df.groupby(group_col)['salary_numeric'].transform('mean')\n",
    "    df[f'avg_salary_by_{group_col}'] = avg_salary\n",
    "    return df\n",
    "\n",
    "def add_salaries_per_reported(df):\n",
    "    \"\"\"\n",
    "    Calculates the ratio of total salary to salaries reported.\n",
    "    \"\"\"\n",
    "    df['salaries_per_reported'] = df['salary_numeric'] / df['salaries_reported']\n",
    "    return df\n",
    "\n",
    "def extract_job_seniority(df):\n",
    "    \"\"\"\n",
    "    Extracts job seniority level from job title.\n",
    "    \"\"\"\n",
    "    def seniority_level(title):\n",
    "        if 'junior' in title.lower():\n",
    "            return 'Junior'\n",
    "        elif 'senior' in title.lower() or 'lead' in title.lower() or 'manager' in title.lower():\n",
    "            return 'Senior'\n",
    "        else:\n",
    "            return 'Mid-level'\n",
    "    \n",
    "    df['job_seniority'] = df['job_title'].apply(seniority_level)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8a35d3af-9a9a-41cc-ad03-a568c443448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/extract.py\n",
    "\n",
    "from src.feature_engineering import (\n",
    "    convert_salary_to_numeric,\n",
    "    add_salary_band,\n",
    "    compute_avg_salary_by_group,\n",
    "    add_salaries_per_reported,\n",
    "    extract_job_seniority\n",
    ")\n",
    "from utils.config import load_config\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Initialize configurations and logging\n",
    "config = load_config()\n",
    "logging.basicConfig(level=config['logging']['level'])\n",
    "\n",
    "def load_data(file_path=None):\n",
    "    \"\"\"\n",
    "    Loads data from a CSV file into a DataFrame.\n",
    "    Applies initial data cleaning steps like handling missing values and setting data types.\n",
    "    \"\"\"\n",
    "    if file_path is None:\n",
    "        file_path = config['data']['source_file']\n",
    "\n",
    "    try:\n",
    "        logging.info(f\"Loading data from {file_path}\")\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Apply data type conversions and handle missing values\n",
    "        df = handle_missing_values(df)\n",
    "        df = set_column_dtypes(df)\n",
    "\n",
    "        # Apply feature engineering\n",
    "        df = convert_salary_to_numeric(df)\n",
    "        df = add_salary_band(df)\n",
    "        df = compute_avg_salary_by_group(df, group_col='company_name')  # Example: group by company_name\n",
    "        df = add_salaries_per_reported(df)\n",
    "        df = extract_job_seniority(df)\n",
    "\n",
    "        logging.info(\"Data loaded and feature engineering applied successfully\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading data: {e}\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame if there is an error\n",
    "\n",
    "\n",
    "from utils.file_utils import to_snakecase, to_titlecase\n",
    "from utils.config import load_config\n",
    "\n",
    "config = load_config()\n",
    "\n",
    "def standardize_column_names(df, case=\"snake\"):\n",
    "    \"\"\"\n",
    "    Standardizes column names based on the specified case.\n",
    "    \"\"\"\n",
    "    if case == \"snake\":\n",
    "        df.columns = [to_snakecase(col) for col in df.columns]\n",
    "    elif case == \"title\":\n",
    "        df.columns = [to_titlecase(col) for col in df.columns]\n",
    "    return df\n",
    "\n",
    "# In load_data\n",
    "df = standardize_column_names(df, case=config['data']['column_name_case'])\n",
    "\n",
    "def handle_missing_values(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Fills or drops missing values based on configuration settings.\n",
    "    \"\"\"\n",
    "    # Example: Fill numeric columns with mean and drop rows with missing categorical values\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in [float, int]:\n",
    "            df[col].fillna(df[col].mean(), inplace=True)\n",
    "        else:\n",
    "            df[col].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "    logging.info(\"Handled missing values\")\n",
    "    return df\n",
    "\n",
    "def set_column_dtypes(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Sets column data types based on configuration or inferred data types.\n",
    "    \"\"\"\n",
    "    date_format = config['data'].get('date_format', None)\n",
    "\n",
    "    # Set columns to datetime format if date_format is provided\n",
    "    for col in df.columns:\n",
    "        if \"date\" in col.lower() and date_format:\n",
    "            try:\n",
    "                df[col] = pd.to_datetime(df[col], format=date_format)\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Failed to parse dates in column {col}: {e}\")\n",
    "\n",
    "    logging.info(\"Data types set according to configuration\")\n",
    "    return df\n",
    "\n",
    "def validate_data(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Validates the data to ensure it meets basic quality criteria.\n",
    "    Example: Check if critical columns exist and have no missing values.\n",
    "    \"\"\"\n",
    "    required_columns = config['data'].get('required_columns', [])\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "\n",
    "    if missing_columns:\n",
    "        logging.error(f\"Missing required columns: {missing_columns}\")\n",
    "        return False\n",
    "\n",
    "    # Additional custom validations could be added here\n",
    "    logging.info(\"Data validation passed\")\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "from utils.file_utils import to_snakecase, to_titlecase\n",
    "from utils.config import load_config\n",
    "\n",
    "config = load_config()\n",
    "\n",
    "def standardize_column_names(df, case=\"snake\"):\n",
    "    \"\"\"\n",
    "    Standardizes column names based on the specified case.\n",
    "    \"\"\"\n",
    "    if case == \"snake\":\n",
    "        df.columns = [to_snakecase(col) for col in df.columns]\n",
    "    elif case == \"title\":\n",
    "        df.columns = [to_titlecase(col) for col in df.columns]\n",
    "    return df\n",
    "\n",
    "# In load_data\n",
    "df = standardize_column_names(df, case=config['data']['column_name_case'])\n",
    "\n",
    "def handle_missing_values(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Fills or drops missing values based on configuration settings.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in [float, int]:\n",
    "            df[col] = df[col].fillna(df[col].mean())  # Avoid inplace\n",
    "        else:\n",
    "            df[col] = df[col].fillna(\"Unknown\")  # Avoid inplace\n",
    "\n",
    "    logging.info(\"Handled missing values\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def set_column_dtypes(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Sets column data types based on configuration or inferred data types.\n",
    "    \"\"\"\n",
    "    date_format = config['data'].get('date_format', None)\n",
    "\n",
    "    # Set columns to datetime format if date_format is provided\n",
    "    for col in df.columns:\n",
    "        if \"date\" in col.lower() and date_format:\n",
    "            try:\n",
    "                df[col] = pd.to_datetime(df[col], format=date_format)\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Failed to parse dates in column {col}: {e}\")\n",
    "\n",
    "    logging.info(\"Data types set according to configuration\")\n",
    "    return df\n",
    "\n",
    "def validate_data(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Validates the data to ensure it meets basic quality criteria.\n",
    "    Example: Check if critical columns exist and have no missing values.\n",
    "    \"\"\"\n",
    "    required_columns = config['data'].get('required_columns', [])\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "\n",
    "    if missing_columns:\n",
    "        logging.error(f\"Missing required columns: {missing_columns}\")\n",
    "        return False\n",
    "\n",
    "    # Additional custom validations could be added here\n",
    "    logging.info(\"Data validation passed\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c028448b-6efa-4344-b33f-3737a002542d",
   "metadata": {},
   "source": [
    "Calling Load Data in app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d233b9a4-1276-408c-9e1c-e663bf6a75f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from data/salary_dataset.csv\n",
      "/home/tron/git/prism/src/extract.py:43: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(\"Unknown\", inplace=True)\n",
      "/home/tron/git/prism/src/extract.py:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mean(), inplace=True)\n",
      "INFO:root:Handled missing values\n",
      "INFO:root:Data types set according to configuration\n",
      "INFO:root:Data loaded successfully\n",
      "INFO:root:Data validation passed\n",
      "INFO:root:Data validation successful. Proceeding with further analysis.\n"
     ]
    }
   ],
   "source": [
    "from src.extract import load_data, validate_data\n",
    "import logging\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load the data\n",
    "df = load_data()\n",
    "\n",
    "# Validate the data\n",
    "if validate_data(df):\n",
    "    logging.info(\"Data validation successful. Proceeding with further analysis.\")\n",
    "    # Proceed with further analysis if data is valid\n",
    "else:\n",
    "    logging.error(\"Data validation failed. Please check the data source or configuration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "60fc747c-a901-4a7d-82d4-3840f57370f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salaries Reported</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mu Sigma</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>â‚¹6,48,573/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IBM</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>â‚¹11,91,950/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>â‚¹8,36,874/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Impact Analytics</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>â‚¹6,69,578/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>â‚¹9,44,110/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Infosys</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>â‚¹9,08,764/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Capgemini</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>â‚¹9,26,124/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cognizant Technology Solutions</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>â‚¹7,36,708/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Anheuser-Busch InBev</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>â‚¹16,46,721/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fractal</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>â‚¹13,92,960/yr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Company Name       Job Title  Salaries Reported  \\\n",
       "0                        Mu Sigma  Data Scientist              105.0   \n",
       "1                             IBM  Data Scientist               95.0   \n",
       "2       Tata Consultancy Services  Data Scientist               66.0   \n",
       "3                Impact Analytics  Data Scientist               40.0   \n",
       "4                       Accenture  Data Scientist               32.0   \n",
       "5                         Infosys  Data Scientist               30.0   \n",
       "6                       Capgemini  Data Scientist               28.0   \n",
       "7  Cognizant Technology Solutions  Data Scientist               26.0   \n",
       "8            Anheuser-Busch InBev  Data Scientist               25.0   \n",
       "9                         Fractal  Data Scientist               22.0   \n",
       "\n",
       "    Location         Salary  \n",
       "0  Bangalore   â‚¹6,48,573/yr  \n",
       "1  Bangalore  â‚¹11,91,950/yr  \n",
       "2  Bangalore   â‚¹8,36,874/yr  \n",
       "3  Bangalore   â‚¹6,69,578/yr  \n",
       "4  Bangalore   â‚¹9,44,110/yr  \n",
       "5  Bangalore   â‚¹9,08,764/yr  \n",
       "6  Bangalore   â‚¹9,26,124/yr  \n",
       "7  Bangalore   â‚¹7,36,708/yr  \n",
       "8  Bangalore  â‚¹16,46,721/yr  \n",
       "9  Bangalore  â‚¹13,92,960/yr  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e37daf5a-a024-4fe4-9913-a5e712aabb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils/file_utils.py\n",
    "\n",
    "import re\n",
    "\n",
    "def to_snakecase(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts a string to snake_case.\n",
    "    Example: 'Column Name' -> 'column_name'\n",
    "    \"\"\"\n",
    "    # Replace spaces with underscores, remove special characters, and make lowercase\n",
    "    text = re.sub(r'[\\W]+', '_', text).strip().lower()\n",
    "    return text\n",
    "\n",
    "def to_titlecase(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts a string to Title Case.\n",
    "    Example: 'column_name' -> 'Column Name'\n",
    "    \"\"\"\n",
    "    # Split by underscores, capitalize each word, and join with spaces\n",
    "    text = text.replace('_', ' ')\n",
    "    return text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3b328a5f-7f2f-4d49-9989-1ebf664337cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.file_utils import to_snakecase, to_titlecase\n",
    "from utils.config import load_config\n",
    "\n",
    "config = load_config()\n",
    "\n",
    "def standardize_column_names(df, case=\"snake\"):\n",
    "    \"\"\"\n",
    "    Standardizes column names based on the specified case.\n",
    "    \"\"\"\n",
    "    if case == \"snake\":\n",
    "        df.columns = [to_snakecase(col) for col in df.columns]\n",
    "    elif case == \"title\":\n",
    "        df.columns = [to_titlecase(col) for col in df.columns]\n",
    "    return df\n",
    "\n",
    "# In load_data\n",
    "df = standardize_column_names(df, case=config['data']['column_name_case'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "67eb69e4-5088-42fa-b396-ef039b434a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salaries_reported</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mu Sigma</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>â‚¹6,48,573/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IBM</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>â‚¹11,91,950/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>â‚¹8,36,874/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Impact Analytics</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>â‚¹6,69,578/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>â‚¹9,44,110/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Infosys</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>â‚¹9,08,764/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Capgemini</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>â‚¹9,26,124/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cognizant Technology Solutions</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>â‚¹7,36,708/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Anheuser-Busch InBev</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>â‚¹16,46,721/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fractal</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>â‚¹13,92,960/yr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     company_name       job_title  salaries_reported  \\\n",
       "0                        Mu Sigma  Data Scientist              105.0   \n",
       "1                             IBM  Data Scientist               95.0   \n",
       "2       Tata Consultancy Services  Data Scientist               66.0   \n",
       "3                Impact Analytics  Data Scientist               40.0   \n",
       "4                       Accenture  Data Scientist               32.0   \n",
       "5                         Infosys  Data Scientist               30.0   \n",
       "6                       Capgemini  Data Scientist               28.0   \n",
       "7  Cognizant Technology Solutions  Data Scientist               26.0   \n",
       "8            Anheuser-Busch InBev  Data Scientist               25.0   \n",
       "9                         Fractal  Data Scientist               22.0   \n",
       "\n",
       "    location         salary  \n",
       "0  Bangalore   â‚¹6,48,573/yr  \n",
       "1  Bangalore  â‚¹11,91,950/yr  \n",
       "2  Bangalore   â‚¹8,36,874/yr  \n",
       "3  Bangalore   â‚¹6,69,578/yr  \n",
       "4  Bangalore   â‚¹9,44,110/yr  \n",
       "5  Bangalore   â‚¹9,08,764/yr  \n",
       "6  Bangalore   â‚¹9,26,124/yr  \n",
       "7  Bangalore   â‚¹7,36,708/yr  \n",
       "8  Bangalore  â‚¹16,46,721/yr  \n",
       "9  Bangalore  â‚¹13,92,960/yr  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b3ae0a27-c6d7-4105-b373-9856c7cdbae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salaries_reported</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4344</td>\n",
       "      <td>4344</td>\n",
       "      <td>4344.000000</td>\n",
       "      <td>4344</td>\n",
       "      <td>4344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2530</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>3101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>â‚¹10,00,000/yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>41</td>\n",
       "      <td>1844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1584</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.775910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.145342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     company_name       job_title  salaries_reported  \\\n",
       "count                        4344            4344        4344.000000   \n",
       "unique                       2530              26                NaN   \n",
       "top     Tata Consultancy Services  Data Scientist                NaN   \n",
       "freq                           41            1844                NaN   \n",
       "mean                          NaN             NaN           2.775910   \n",
       "std                           NaN             NaN           5.145342   \n",
       "min                           NaN             NaN           1.000000   \n",
       "25%                           NaN             NaN           1.000000   \n",
       "50%                           NaN             NaN           1.000000   \n",
       "75%                           NaN             NaN           3.000000   \n",
       "max                           NaN             NaN         105.000000   \n",
       "\n",
       "         location         salary  \n",
       "count        4344           4344  \n",
       "unique          5           3101  \n",
       "top     Bangalore  â‚¹10,00,000/yr  \n",
       "freq         1584             24  \n",
       "mean          NaN            NaN  \n",
       "std           NaN            NaN  \n",
       "min           NaN            NaN  \n",
       "25%           NaN            NaN  \n",
       "50%           NaN            NaN  \n",
       "75%           NaN            NaN  \n",
       "max           NaN            NaN  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "563dda06-3a2f-4198-9127-675627409c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Handled missing values\n",
      "INFO:root:Data types set according to configuration\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '41271/mo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m set_column_dtypes(df)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Apply feature engineering\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_salary_to_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m df \u001b[38;5;241m=\u001b[39m add_salary_band(df)\n\u001b[1;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m compute_avg_salary_by_group(df, group_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompany_name\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Example: group by company_name\u001b[39;00m\n",
      "File \u001b[0;32m~/git/prism/src/feature_engineering.py:10\u001b[0m, in \u001b[0;36mconvert_salary_to_numeric\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_salary_to_numeric\u001b[39m(df):\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    Converts the 'salary' column to a numeric format (removes currency symbols, commas).\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalary_numeric\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msalary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mâ‚¹\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/yr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/prism-DZtde6Gu/lib/python3.12/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/prism-DZtde6Gu/lib/python3.12/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/prism-DZtde6Gu/lib/python3.12/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/prism-DZtde6Gu/lib/python3.12/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/prism-DZtde6Gu/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/prism-DZtde6Gu/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/prism-DZtde6Gu/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '41271/mo'"
     ]
    }
   ],
   "source": [
    "df = handle_missing_values(df)\n",
    "df = set_column_dtypes(df)\n",
    "\n",
    "# Apply feature engineering\n",
    "df = convert_salary_to_numeric(df)\n",
    "df = add_salary_band(df)\n",
    "df = compute_avg_salary_by_group(df, group_col='company_name')  # Example: group by company_name\n",
    "df = add_salaries_per_reported(df)\n",
    "df = extract_job_seniority(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ec9d80-6ef3-480b-af8f-ab9a2f91be8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8906bc37-9179-4766-8710-18198302bc7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
